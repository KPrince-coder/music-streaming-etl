{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into RDS\n",
    "\n",
    "Two different data are loaded into RDS:\n",
    "1. user metadata\n",
    "2. song metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from io import StringIO\n",
    "from contextlib import contextmanager\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\DOJO\\VSCode Project\\Notebooks\\Labs\\Phase_II_labs\\1_music_streaming\\dags\\music_streaming\\loaders\n",
      "Root Directory: c:\\DOJO\\VSCode Project\\Notebooks\\Labs\\Phase_II_labs\\1_music_streaming\n",
      "Data Directory: c:\\DOJO\\VSCode Project\\Notebooks\\Labs\\Phase_II_labs\\1_music_streaming\\data\n"
     ]
    }
   ],
   "source": [
    "# Database connection configuration\n",
    "DB_HOST = \"lab-db12.czaiaq68azf6.eu-west-1.rds.amazonaws.com\"\n",
    "DB_NAME = \"music_db\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"lab-db12\"\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": DB_HOST,\n",
    "    \"dbname\": DB_NAME,\n",
    "    \"user\": DB_USER,\n",
    "    \"password\": DB_PASSWORD,\n",
    "}\n",
    "\n",
    "# File paths configuration\n",
    "# Get the current working directory and navigate to the root\n",
    "CURRENT_DIR = os.getcwd()  # Get current working directory\n",
    "# Assuming we're in dags/music_streaming/loaders\n",
    "ROOT_DIR = os.path.dirname(\n",
    "    os.path.dirname(os.path.dirname(CURRENT_DIR))\n",
    ")  # Go up 3 levels\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")  # Path to data directory\n",
    "\n",
    "# Debug print to verify paths\n",
    "print(f\"Current Directory: {CURRENT_DIR}\")\n",
    "print(f\"Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "\n",
    "# CSV file paths relative to DATA_DIR\n",
    "USER_CSV_FILE = \"users/users.csv\"\n",
    "SONG_CSV_FILE = \"songs/songs.csv\"\n",
    "\n",
    "# Database table names\n",
    "USER_TABLE = \"users\"\n",
    "SONG_TABLE = \"songs\"\n",
    "\n",
    "# Batch processing size\n",
    "CHUNK_SIZE = 50_000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a context manager for PostgreSQL connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def postgres_connection():\n",
    "    \"\"\"\n",
    "    Context manager for PostgreSQL connection.\n",
    "\n",
    "    Yields:\n",
    "        connection: PostgreSQL connection object\n",
    "\n",
    "    Ensures proper connection handling and cleanup.\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        yield conn\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV Data into RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_table(csv_path: str, table_name: str):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into a specified PostgreSQL table.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Full path to the CSV file\n",
    "        table_name (str): Name of the target database table\n",
    "    \"\"\"\n",
    "    # Column mapping for songs table\n",
    "    column_mappings = {\n",
    "        \"songs\": {\n",
    "            \"key\": \"song_key\"  # Map 'key' from CSV to 'song_key' in database\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with postgres_connection() as conn:\n",
    "            # Read CSV headers\n",
    "            df = pd.read_csv(csv_path, nrows=0)\n",
    "            columns = list(df.columns)\n",
    "\n",
    "            # Apply column mapping if exists\n",
    "            if table_name in column_mappings:\n",
    "                for old_col, new_col in column_mappings[table_name].items():\n",
    "                    if old_col in columns:\n",
    "                        columns[columns.index(old_col)] = new_col\n",
    "\n",
    "            # Process in chunks\n",
    "            for chunk in pd.read_csv(csv_path, chunksize=CHUNK_SIZE):\n",
    "                # Rename columns according to mapping\n",
    "                if table_name in column_mappings:\n",
    "                    chunk = chunk.rename(columns=column_mappings[table_name])\n",
    "\n",
    "                # Handle NaN values\n",
    "                chunk = chunk.where(pd.notnull(chunk), None)\n",
    "\n",
    "                with StringIO() as buffer:\n",
    "                    chunk.to_csv(buffer, index=False, header=False)\n",
    "                    buffer.seek(0)\n",
    "\n",
    "                    with conn.cursor() as cursor:\n",
    "                        copy_sql = f\"\"\"\n",
    "                            COPY {table_name} ({\",\".join(columns)})\n",
    "                            FROM STDIN WITH CSV\n",
    "                        \"\"\"\n",
    "                        cursor.copy_expert(copy_sql, buffer)\n",
    "                        conn.commit()\n",
    "\n",
    "            print(f\"Successfully loaded {os.path.basename(csv_path)} → {table_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {csv_path}: {str(e)}\")\n",
    "        if \"conn\" in locals() and conn and not conn.closed:\n",
    "            conn.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_csv_to_table(csv_path: str, table_name: str):\n",
    "#     \"\"\"\n",
    "#     Load data from a CSV file into a specified PostgreSQL table.\n",
    "\n",
    "#     Args:\n",
    "#         csv_path (str): Full path to the CSV file\n",
    "#         table_name (str): Name of the target database table\n",
    "\n",
    "#     Handles data in chunks to manage memory efficiently and properly handles NULL values.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         with postgres_connection() as conn:\n",
    "#             # Get CSV headers for COPY command\n",
    "#             with open(csv_path, \"r\") as f:\n",
    "#                 columns = f.readline().strip().split(\",\")\n",
    "\n",
    "#             # Process in chunks\n",
    "#             for chunk in pd.read_csv(csv_path, chunksize=CHUNK_SIZE):\n",
    "#                 # Handle NaN values by converting them to None (NULL in PostgreSQL)\n",
    "#                 chunk = chunk.where(pd.notnull(chunk), None)\n",
    "\n",
    "#                 with StringIO() as buffer:\n",
    "#                     chunk.to_csv(buffer, index=False, header=False)\n",
    "#                     buffer.seek(0)\n",
    "\n",
    "#                     with conn.cursor() as cursor:\n",
    "#                         copy_sql = f\"\"\"\n",
    "#                             COPY {table_name} ({\",\".join(columns)})\n",
    "#                             FROM STDIN WITH CSV\n",
    "#                         \"\"\"\n",
    "#                         cursor.copy_expert(copy_sql, buffer)\n",
    "#                         conn.commit()\n",
    "\n",
    "#             print(f\"Successfully loaded {os.path.basename(csv_path)} → {table_name}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading {csv_path}: {str(e)}\")\n",
    "#         if \"conn\" in locals():\n",
    "#             conn.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    Main function to process and load data into database tables.\n",
    "\n",
    "    Handles the loading of all CSV files into their respective database tables,\n",
    "    creating necessary directories if they don't exist.\n",
    "    \"\"\"\n",
    "    file_table_mapping = {\n",
    "        USER_CSV_FILE: USER_TABLE,\n",
    "        SONG_CSV_FILE: SONG_TABLE,\n",
    "    }\n",
    "\n",
    "    print(f\"Data directory path: {DATA_DIR}\")  # Debug print\n",
    "\n",
    "    for csv_file, table_name in file_table_mapping.items():\n",
    "        # Create full path by joining DATA_DIR with the CSV file path\n",
    "        csv_path = os.path.join(DATA_DIR, csv_file)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"Attempting to load: {csv_path}\")\n",
    "\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "        if os.path.exists(csv_path):\n",
    "            load_csv_to_table(csv_path, table_name)\n",
    "            print(f\"File found: {csv_path}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"File not found: {csv_path}\")\n",
    "            print(\"Please ensure the file exists at the specified location\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from CSV files into PostgreSQL tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory path: c:\\DOJO\\VSCode Project\\Notebooks\\Labs\\Phase_II_labs\\1_music_streaming\\data\n",
      "Attempting to load: c:\\DOJO\\VSCode Project\\Notebooks\\Labs\\Phase_II_labs\\1_music_streaming\\data\\users/users.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded users.csv → users\n",
      "Attempting to load: c:\\DOJO\\VSCode Project\\Notebooks\\Labs\\Phase_II_labs\\1_music_streaming\\data\\songs/songs.csv\n",
      "Successfully loaded songs.csv → songs\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    load_all_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".music-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
